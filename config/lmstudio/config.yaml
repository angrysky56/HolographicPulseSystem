server:
  host: "0.0.0.0"
  port: 1234
  model_path: "./models/meta-llama-3.1-8b-instruct-abliterated"
  embedding_model: "text-embedding-nomic-embed-text-v1.5@Q8_0"
  max_total_tokens: 4096
  max_input_length: 2048
  context_window: 8192
  temperature: 0.7
  repeat_penalty: 1.1
  threads: 8

metrics:
  enabled: true
  port: 9100
  path: "/metrics"

logging:
  level: "info"
  file: "./logs/lmstudio.log"